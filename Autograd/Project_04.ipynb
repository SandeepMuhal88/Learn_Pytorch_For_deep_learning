{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dffe9b86",
   "metadata": {},
   "source": [
    "### Mini Project: Linear Regression with Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fb021930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0f4835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[1.0],[2.0],[3.0],[4.0]]) \n",
    "y=torch.tensor([[5.0],[9.0],[6.0],[8.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc3af0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce2b1d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [9.],\n",
       "        [6.],\n",
       "        [8.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd1ecbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight: 3.039306879043579, Initial bias: 0.054034050554037094\n"
     ]
    }
   ],
   "source": [
    "w= torch.randn(1, requires_grad=True)\n",
    "b= torch.randn(1, requires_grad=True)\n",
    "print(f\"Initial weight: {w.item()}, Initial bias: {b.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4efcb428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0393], requires_grad=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "585c98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "217c6f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: w = 2.5413, b = 0.0700, loss = 7.152752\n",
      "Epoch 20: w = 2.4154, b = 0.2071, loss = 6.767667\n",
      "Epoch 30: w = 2.3508, b = 0.3597, loss = 6.490796\n",
      "Epoch 40: w = 2.2973, b = 0.5109, loss = 6.232259\n",
      "Epoch 50: w = 2.2469, b = 0.6582, loss = 5.988828\n",
      "Epoch 60: w = 2.1982, b = 0.8012, loss = 5.759568\n",
      "Epoch 70: w = 2.1510, b = 0.9400, loss = 5.543652\n",
      "Epoch 80: w = 2.1051, b = 1.0747, loss = 5.340303\n",
      "Epoch 90: w = 2.0607, b = 1.2054, loss = 5.148790\n",
      "Epoch 100: w = 2.0175, b = 1.3323, loss = 4.968424\n",
      "Epoch 110: w = 1.9757, b = 1.4554, loss = 4.798557\n",
      "Epoch 120: w = 1.9350, b = 1.5749, loss = 4.638577\n",
      "Epoch 130: w = 1.8956, b = 1.6908, loss = 4.487908\n",
      "Epoch 140: w = 1.8573, b = 1.8033, loss = 4.346009\n",
      "Epoch 150: w = 1.8202, b = 1.9125, loss = 4.212369\n",
      "Epoch 160: w = 1.7841, b = 2.0185, loss = 4.086509\n",
      "Epoch 170: w = 1.7492, b = 2.1213, loss = 3.967973\n",
      "Epoch 180: w = 1.7152, b = 2.2211, loss = 3.856337\n",
      "Epoch 190: w = 1.6823, b = 2.3180, loss = 3.751198\n",
      "Epoch 200: w = 1.6503, b = 2.4120, loss = 3.652180\n",
      "Epoch 210: w = 1.6193, b = 2.5032, loss = 3.558925\n",
      "Epoch 220: w = 1.5892, b = 2.5917, loss = 3.471097\n",
      "Epoch 230: w = 1.5599, b = 2.6776, loss = 3.388382\n",
      "Epoch 240: w = 1.5316, b = 2.7610, loss = 3.310481\n",
      "Epoch 250: w = 1.5041, b = 2.8419, loss = 3.237115\n",
      "Epoch 260: w = 1.4774, b = 2.9204, loss = 3.168018\n",
      "Epoch 270: w = 1.4515, b = 2.9966, loss = 3.102943\n",
      "Epoch 280: w = 1.4263, b = 3.0706, loss = 3.041656\n",
      "Epoch 290: w = 1.4019, b = 3.1423, loss = 2.983937\n",
      "Epoch 300: w = 1.3782, b = 3.2120, loss = 2.929578\n",
      "Epoch 310: w = 1.3552, b = 3.2796, loss = 2.878381\n",
      "Epoch 320: w = 1.3329, b = 3.3452, loss = 2.830165\n",
      "Epoch 330: w = 1.3113, b = 3.4088, loss = 2.784756\n",
      "Epoch 340: w = 1.2903, b = 3.4706, loss = 2.741988\n",
      "Epoch 350: w = 1.2699, b = 3.5305, loss = 2.701711\n",
      "Epoch 360: w = 1.2501, b = 3.5887, loss = 2.663778\n",
      "Epoch 370: w = 1.2309, b = 3.6452, loss = 2.628053\n",
      "Epoch 380: w = 1.2122, b = 3.6999, loss = 2.594408\n",
      "Epoch 390: w = 1.1942, b = 3.7531, loss = 2.562720\n",
      "Epoch 400: w = 1.1766, b = 3.8047, loss = 2.532877\n",
      "Epoch 410: w = 1.1596, b = 3.8548, loss = 2.504772\n",
      "Epoch 420: w = 1.1430, b = 3.9034, loss = 2.478302\n",
      "Epoch 430: w = 1.1270, b = 3.9506, loss = 2.453372\n",
      "Epoch 440: w = 1.1114, b = 3.9963, loss = 2.429893\n",
      "Epoch 450: w = 1.0963, b = 4.0407, loss = 2.407782\n",
      "Epoch 460: w = 1.0817, b = 4.0838, loss = 2.386957\n",
      "Epoch 470: w = 1.0674, b = 4.1257, loss = 2.367344\n",
      "Epoch 480: w = 1.0536, b = 4.1663, loss = 2.348873\n",
      "Epoch 490: w = 1.0402, b = 4.2057, loss = 2.331476\n",
      "Epoch 500: w = 1.0272, b = 4.2439, loss = 2.315094\n",
      "Epoch 510: w = 1.0146, b = 4.2810, loss = 2.299663\n",
      "Epoch 520: w = 1.0024, b = 4.3170, loss = 2.285131\n",
      "Epoch 530: w = 0.9905, b = 4.3520, loss = 2.271446\n",
      "Epoch 540: w = 0.9789, b = 4.3859, loss = 2.258556\n",
      "Epoch 550: w = 0.9677, b = 4.4188, loss = 2.246418\n",
      "Epoch 560: w = 0.9569, b = 4.4507, loss = 2.234985\n",
      "Epoch 570: w = 0.9463, b = 4.4817, loss = 2.224217\n",
      "Epoch 580: w = 0.9361, b = 4.5118, loss = 2.214077\n",
      "Epoch 590: w = 0.9262, b = 4.5410, loss = 2.204527\n",
      "Epoch 600: w = 0.9165, b = 4.5693, loss = 2.195533\n",
      "Epoch 610: w = 0.9072, b = 4.5968, loss = 2.187062\n",
      "Epoch 620: w = 0.8981, b = 4.6235, loss = 2.179084\n",
      "Epoch 630: w = 0.8893, b = 4.6494, loss = 2.171571\n",
      "Epoch 640: w = 0.8808, b = 4.6745, loss = 2.164495\n",
      "Epoch 650: w = 0.8725, b = 4.6989, loss = 2.157831\n",
      "Epoch 660: w = 0.8644, b = 4.7225, loss = 2.151554\n",
      "Epoch 670: w = 0.8566, b = 4.7455, loss = 2.145643\n",
      "Epoch 680: w = 0.8490, b = 4.7678, loss = 2.140076\n",
      "Epoch 690: w = 0.8417, b = 4.7894, loss = 2.134833\n",
      "Epoch 700: w = 0.8345, b = 4.8104, loss = 2.129896\n",
      "Epoch 710: w = 0.8276, b = 4.8308, loss = 2.125246\n",
      "Epoch 720: w = 0.8209, b = 4.8506, loss = 2.120866\n",
      "Epoch 730: w = 0.8144, b = 4.8697, loss = 2.116741\n",
      "Epoch 740: w = 0.8080, b = 4.8884, loss = 2.112856\n",
      "Epoch 750: w = 0.8019, b = 4.9064, loss = 2.109198\n",
      "Epoch 760: w = 0.7959, b = 4.9240, loss = 2.105752\n",
      "Epoch 770: w = 0.7901, b = 4.9410, loss = 2.102507\n",
      "Epoch 780: w = 0.7845, b = 4.9575, loss = 2.099451\n",
      "Epoch 790: w = 0.7791, b = 4.9735, loss = 2.096573\n",
      "Epoch 800: w = 0.7738, b = 4.9891, loss = 2.093862\n",
      "Epoch 810: w = 0.7686, b = 5.0042, loss = 2.091309\n",
      "Epoch 820: w = 0.7637, b = 5.0188, loss = 2.088905\n",
      "Epoch 830: w = 0.7588, b = 5.0330, loss = 2.086640\n",
      "Epoch 840: w = 0.7541, b = 5.0468, loss = 2.084507\n",
      "Epoch 850: w = 0.7496, b = 5.0602, loss = 2.082498\n",
      "Epoch 860: w = 0.7452, b = 5.0732, loss = 2.080607\n",
      "Epoch 870: w = 0.7409, b = 5.0858, loss = 2.078826\n",
      "Epoch 880: w = 0.7367, b = 5.0980, loss = 2.077148\n",
      "Epoch 890: w = 0.7327, b = 5.1099, loss = 2.075568\n",
      "Epoch 900: w = 0.7288, b = 5.1214, loss = 2.074080\n",
      "Epoch 910: w = 0.7250, b = 5.1326, loss = 2.072678\n",
      "Epoch 920: w = 0.7213, b = 5.1435, loss = 2.071358\n",
      "Epoch 930: w = 0.7177, b = 5.1540, loss = 2.070115\n",
      "Epoch 940: w = 0.7142, b = 5.1642, loss = 2.068944\n",
      "Epoch 950: w = 0.7108, b = 5.1741, loss = 2.067841\n",
      "Epoch 960: w = 0.7076, b = 5.1838, loss = 2.066803\n",
      "Epoch 970: w = 0.7044, b = 5.1931, loss = 2.065825\n",
      "Epoch 980: w = 0.7013, b = 5.2022, loss = 2.064904\n",
      "Epoch 990: w = 0.6983, b = 5.2110, loss = 2.064036\n",
      "Epoch 1000: w = 0.6954, b = 5.2195, loss = 2.063220\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    # Forward pass: predict y\n",
    "    y_pred = x * w + b\n",
    "    \n",
    "    # Compute loss mse(mean squared error)\n",
    "    loss = torch.mean((y_pred - y) ** 2)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "        \n",
    "        # Zero gradients after update\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: w = {w.item():.4f}, b = {b.item():.4f}, loss = {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85295890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model: y = 0.6954x + 5.2195\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Model: y = {:.4f}x + {:.4f}\".format(w.item(), b.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d2e587b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m s\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m s\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "s=torch.tensor([1,2,3,4,5],requires_grad=True)\n",
    "s"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
