{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dffe9b86",
   "metadata": {},
   "source": [
    "### Mini Project: Linear Regression with Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb021930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0f4835a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor([[1.0],[2.0],[3.0],[4.0]]) \n",
    "y=torch.tensor([[5.0],[9.0],[6.0],[8.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3af0b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.],\n",
       "        [2.],\n",
       "        [3.],\n",
       "        [4.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce2b1d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5.],\n",
       "        [9.],\n",
       "        [6.],\n",
       "        [8.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1ecbb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight: -0.15965962409973145, Initial bias: -0.856700599193573\n"
     ]
    }
   ],
   "source": [
    "w= torch.randn(1, requires_grad=True)\n",
    "b= torch.randn(1, requires_grad=True)\n",
    "print(f\"Initial weight: {w.item()}, Initial bias: {b.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4efcb428",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1597], requires_grad=True)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "585c98aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=0.01\n",
    "epochs=1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "217c6f83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: w = 1.9830, b = 0.0522, loss = 9.159947\n",
      "Epoch 20: w = 2.2831, b = 0.3291, loss = 6.564144\n",
      "Epoch 30: w = 2.2883, b = 0.5005, loss = 6.244944\n",
      "Epoch 40: w = 2.2472, b = 0.6512, loss = 5.999316\n",
      "Epoch 50: w = 2.2000, b = 0.7949, loss = 5.769408\n",
      "Epoch 60: w = 2.1530, b = 0.9340, loss = 5.552917\n",
      "Epoch 70: w = 2.1071, b = 1.0688, loss = 5.349029\n",
      "Epoch 80: w = 2.0626, b = 1.1997, loss = 5.157009\n",
      "Epoch 90: w = 2.0194, b = 1.3268, loss = 4.976165\n",
      "Epoch 100: w = 1.9775, b = 1.4500, loss = 4.805847\n",
      "Epoch 110: w = 1.9368, b = 1.5697, loss = 4.645442\n",
      "Epoch 120: w = 1.8973, b = 1.6858, loss = 4.494374\n",
      "Epoch 130: w = 1.8590, b = 1.7984, loss = 4.352099\n",
      "Epoch 140: w = 1.8218, b = 1.9078, loss = 4.218105\n",
      "Epoch 150: w = 1.7857, b = 2.0139, loss = 4.091910\n",
      "Epoch 160: w = 1.7507, b = 2.1169, loss = 3.973060\n",
      "Epoch 170: w = 1.7167, b = 2.2168, loss = 3.861128\n",
      "Epoch 180: w = 1.6837, b = 2.3138, loss = 3.755711\n",
      "Epoch 190: w = 1.6517, b = 2.4079, loss = 3.656430\n",
      "Epoch 200: w = 1.6206, b = 2.4992, loss = 3.562928\n",
      "Epoch 210: w = 1.5905, b = 2.5879, loss = 3.474868\n",
      "Epoch 220: w = 1.5612, b = 2.6739, loss = 3.391932\n",
      "Epoch 230: w = 1.5328, b = 2.7574, loss = 3.313825\n",
      "Epoch 240: w = 1.5053, b = 2.8384, loss = 3.240264\n",
      "Epoch 250: w = 1.4785, b = 2.9170, loss = 3.170985\n",
      "Epoch 260: w = 1.4526, b = 2.9933, loss = 3.105738\n",
      "Epoch 270: w = 1.4274, b = 3.0673, loss = 3.044287\n",
      "Epoch 280: w = 1.4030, b = 3.1392, loss = 2.986414\n",
      "Epoch 290: w = 1.3792, b = 3.2089, loss = 2.931911\n",
      "Epoch 300: w = 1.3562, b = 3.2766, loss = 2.880579\n",
      "Epoch 310: w = 1.3339, b = 3.3423, loss = 2.832234\n",
      "Epoch 320: w = 1.3122, b = 3.4060, loss = 2.786705\n",
      "Epoch 330: w = 1.2912, b = 3.4679, loss = 2.743824\n",
      "Epoch 340: w = 1.2708, b = 3.5279, loss = 2.703440\n",
      "Epoch 350: w = 1.2509, b = 3.5862, loss = 2.665407\n",
      "Epoch 360: w = 1.2317, b = 3.6427, loss = 2.629586\n",
      "Epoch 370: w = 1.2130, b = 3.6976, loss = 2.595852\n",
      "Epoch 380: w = 1.1949, b = 3.7508, loss = 2.564080\n",
      "Epoch 390: w = 1.1774, b = 3.8025, loss = 2.534158\n",
      "Epoch 400: w = 1.1603, b = 3.8526, loss = 2.505977\n",
      "Epoch 410: w = 1.1438, b = 3.9013, loss = 2.479437\n",
      "Epoch 420: w = 1.1277, b = 3.9485, loss = 2.454442\n",
      "Epoch 430: w = 1.1121, b = 3.9943, loss = 2.430901\n",
      "Epoch 440: w = 1.0970, b = 4.0388, loss = 2.408731\n",
      "Epoch 450: w = 1.0823, b = 4.0820, loss = 2.387851\n",
      "Epoch 460: w = 1.0681, b = 4.1239, loss = 2.368186\n",
      "Epoch 470: w = 1.0542, b = 4.1645, loss = 2.349666\n",
      "Epoch 480: w = 1.0408, b = 4.2040, loss = 2.332224\n",
      "Epoch 490: w = 1.0278, b = 4.2422, loss = 2.315797\n",
      "Epoch 500: w = 1.0152, b = 4.2794, loss = 2.300327\n",
      "Epoch 510: w = 1.0029, b = 4.3154, loss = 2.285756\n",
      "Epoch 520: w = 0.9910, b = 4.3504, loss = 2.272034\n",
      "Epoch 530: w = 0.9794, b = 4.3844, loss = 2.259110\n",
      "Epoch 540: w = 0.9682, b = 4.4173, loss = 2.246939\n",
      "Epoch 550: w = 0.9574, b = 4.4493, loss = 2.235476\n",
      "Epoch 560: w = 0.9468, b = 4.4804, loss = 2.224680\n",
      "Epoch 570: w = 0.9366, b = 4.5105, loss = 2.214513\n",
      "Epoch 580: w = 0.9266, b = 4.5397, loss = 2.204937\n",
      "Epoch 590: w = 0.9170, b = 4.5681, loss = 2.195919\n",
      "Epoch 600: w = 0.9076, b = 4.5956, loss = 2.187426\n",
      "Epoch 610: w = 0.8985, b = 4.6223, loss = 2.179428\n",
      "Epoch 620: w = 0.8897, b = 4.6482, loss = 2.171894\n",
      "Epoch 630: w = 0.8811, b = 4.6734, loss = 2.164799\n",
      "Epoch 640: w = 0.8728, b = 4.6978, loss = 2.158118\n",
      "Epoch 650: w = 0.8648, b = 4.7215, loss = 2.151824\n",
      "Epoch 660: w = 0.8570, b = 4.7445, loss = 2.145897\n",
      "Epoch 670: w = 0.8494, b = 4.7668, loss = 2.140316\n",
      "Epoch 680: w = 0.8420, b = 4.7885, loss = 2.135059\n",
      "Epoch 690: w = 0.8349, b = 4.8095, loss = 2.130108\n",
      "Epoch 700: w = 0.8279, b = 4.8299, loss = 2.125445\n",
      "Epoch 710: w = 0.8212, b = 4.8497, loss = 2.121054\n",
      "Epoch 720: w = 0.8146, b = 4.8689, loss = 2.116919\n",
      "Epoch 730: w = 0.8083, b = 4.8875, loss = 2.113024\n",
      "Epoch 740: w = 0.8022, b = 4.9056, loss = 2.109355\n",
      "Epoch 750: w = 0.7962, b = 4.9232, loss = 2.105901\n",
      "Epoch 760: w = 0.7904, b = 4.9402, loss = 2.102647\n",
      "Epoch 770: w = 0.7848, b = 4.9568, loss = 2.099582\n",
      "Epoch 780: w = 0.7793, b = 4.9728, loss = 2.096697\n",
      "Epoch 790: w = 0.7740, b = 4.9884, loss = 2.093979\n",
      "Epoch 800: w = 0.7689, b = 5.0035, loss = 2.091419\n",
      "Epoch 810: w = 0.7639, b = 5.0182, loss = 2.089008\n",
      "Epoch 820: w = 0.7590, b = 5.0324, loss = 2.086738\n",
      "Epoch 830: w = 0.7543, b = 5.0462, loss = 2.084599\n",
      "Epoch 840: w = 0.7498, b = 5.0596, loss = 2.082586\n",
      "Epoch 850: w = 0.7454, b = 5.0726, loss = 2.080689\n",
      "Epoch 860: w = 0.7411, b = 5.0852, loss = 2.078903\n",
      "Epoch 870: w = 0.7369, b = 5.0975, loss = 2.077220\n",
      "Epoch 880: w = 0.7329, b = 5.1094, loss = 2.075636\n",
      "Epoch 890: w = 0.7289, b = 5.1209, loss = 2.074144\n",
      "Epoch 900: w = 0.7251, b = 5.1321, loss = 2.072738\n",
      "Epoch 910: w = 0.7214, b = 5.1430, loss = 2.071415\n",
      "Epoch 920: w = 0.7178, b = 5.1535, loss = 2.070169\n",
      "Epoch 930: w = 0.7144, b = 5.1638, loss = 2.068995\n",
      "Epoch 940: w = 0.7110, b = 5.1737, loss = 2.067889\n",
      "Epoch 950: w = 0.7077, b = 5.1833, loss = 2.066848\n",
      "Epoch 960: w = 0.7045, b = 5.1927, loss = 2.065868\n",
      "Epoch 970: w = 0.7014, b = 5.2018, loss = 2.064943\n",
      "Epoch 980: w = 0.6984, b = 5.2106, loss = 2.064074\n",
      "Epoch 990: w = 0.6955, b = 5.2191, loss = 2.063255\n",
      "Epoch 1000: w = 0.6927, b = 5.2274, loss = 2.062484\n"
     ]
    }
   ],
   "source": [
    "#Training loop\n",
    "\n",
    "for epoch in range(epochs): \n",
    "    # Forward pass: predict y\n",
    "    y_pred = x * w + b\n",
    "    \n",
    "    # Compute loss mse(mean squared error)\n",
    "    loss = torch.mean((y_pred - y) ** 2)\n",
    "    \n",
    "    # Backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    # Update weights\n",
    "    with torch.no_grad():\n",
    "        w -= lr * w.grad\n",
    "        b -= lr * b.grad\n",
    "        \n",
    "        # Zero gradients after update\n",
    "        w.grad.zero_()\n",
    "        b.grad.zero_()\n",
    "    # Print progress\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch+1}: w = {w.item():.4f}, b = {b.item():.4f}, loss = {loss.item():.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "85295890",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Model: y = 0.6927x + 5.2274\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nFinal Model: y = {:.4f}x + {:.4f}\".format(w.item(), b.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d2e587b",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m s\u001b[38;5;241m=\u001b[39m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "s=torch.tensor([1,2,3,4,5],requires_grad=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
